{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fake News Prediction in ML using Logistic Regression model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import  PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dowload the stopwords by using natural language toolkit(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Madina\n",
      "[nltk_data]     Computers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check to find which are the stopwords so that they will remove from the any text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset = pd.read_csv('fake_news_dataset.csv')\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "news_dataset.csv: A full news dataset with the following attributes:\n",
    "\n",
    "id: unique id for a news article\n",
    "\n",
    "title: the title of a news article\n",
    "\n",
    "author: author of the news article\n",
    "\n",
    "text: the text of the article; could be incomplete\n",
    "\n",
    "label: a label that marks the article as potentially unreliable\n",
    "\n",
    "1 = unreliable(fake)\n",
    "\n",
    "0 = reliable(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           id                                              title  \\\n",
       "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2          2                  Why the Truth Might Get You Fired   \n",
       "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4          4  Iranian woman jailed for fictional unpublished...   \n",
       "...      ...                                                ...   \n",
       "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "20799  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                  Darrell Lucus   \n",
       "1                                Daniel J. Flynn   \n",
       "2                             Consortiumnews.com   \n",
       "3                                Jessica Purkiss   \n",
       "4                                 Howard Portnoy   \n",
       "...                                          ...   \n",
       "20795                              Jerome Hudson   \n",
       "20796                           Benjamin Hoffman   \n",
       "20797  Michael J. de la Merced and Rachel Abrams   \n",
       "20798                                Alex Ansary   \n",
       "20799                              David Swanson   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "...                                                  ...    ...  \n",
       "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "20796  When the Green Bay Packers lost to the Washing...      0  \n",
       "20797  The Macy’s of today grew from the union of sev...      0  \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "20799    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[20800 rows x 5 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  20800.000000  20800.000000\n",
       "mean   10399.500000      0.500625\n",
       "std     6004.587135      0.500012\n",
       "min        0.000000      0.000000\n",
       "25%     5199.750000      0.000000\n",
       "50%    10399.500000      1.000000\n",
       "75%    15599.250000      1.000000\n",
       "max    20799.000000      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the number of missing values in our dataset either present or not if present then how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so there is null values in our dataset but not too much that can affect our precess or prediction so that we replace it with 'Nan' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = news_dataset.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all 3 features ,but it will slow down our processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_dataset['content'] = news_dataset['author']+ ' ' +news_dataset['title']+' ' +news_dataset['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 2 features, cancatenate them !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['content'] = news_dataset['author']+ '     ' +news_dataset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Darrell Lucus     House Dem Aide: We Didn’t Ev...\n",
       "1        Daniel J. Flynn     FLYNN: Hillary Clinton, Bi...\n",
       "2        Consortiumnews.com     Why the Truth Might Get...\n",
       "3        Jessica Purkiss     15 Civilians Killed In Sin...\n",
       "4        Howard Portnoy     Iranian woman jailed for fi...\n",
       "                               ...                        \n",
       "20795    Jerome Hudson     Rapper T.I.: Trump a ’Poster...\n",
       "20796    Benjamin Hoffman     N.F.L. Playoffs: Schedule...\n",
       "20797    Michael J. de la Merced and Rachel Abrams     ...\n",
       "20798    Alex Ansary     NATO, Russia To Hold Parallel ...\n",
       "20799          David Swanson     What Keeps the F-35 Alive\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separating the features(x) and labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = news_dataset.drop(columns='label' , axis=1)\n",
    "y = news_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus     House Dem Aide: We Didn’t Ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>Daniel J. Flynn     FLYNN: Hillary Clinton, Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>Consortiumnews.com     Why the Truth Might Get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>Jessica Purkiss     15 Civilians Killed In Sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>Howard Portnoy     Iranian woman jailed for fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  Ever get the feeling your life circles the rou...   \n",
       "2  Why the Truth Might Get You Fired October 29, ...   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...   \n",
       "\n",
       "                                             content  \n",
       "0  Darrell Lucus     House Dem Aide: We Didn’t Ev...  \n",
       "1  Daniel J. Flynn     FLYNN: Hillary Clinton, Bi...  \n",
       "2  Consortiumnews.com     Why the Truth Might Get...  \n",
       "3  Jessica Purkiss     15 Civilians Killed In Sin...  \n",
       "4  Howard Portnoy     Iranian woman jailed for fi...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the module that remove unecessory things excluding specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, and “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”.\n",
    "\n",
    "Some more example of stemming for root word \"like\" include:\n",
    "\n",
    "-> \"likes\"\n",
    "-> \"liked\"\n",
    "-> \"likely\"\n",
    "-> \"liking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    #substituting by the use of regular expression's function\n",
    "    stemmed_data = re.sub('[^a-zA-Z]',' ',content)\n",
    "    #converting all text into lower case alphabets\n",
    "    stemmed_data = stemmed_data.lower()\n",
    "    #split() method splits a string into a list\n",
    "    stemmed_data = stemmed_data.split()\n",
    "    #removing stopwords\n",
    "    stemmed_data = [port_stem.stem(word) for word in stemmed_data if not word in stopwords.words('english')]\n",
    "    #collecting words other than stopwords \n",
    "    stemmed_data = ' '.join(stemmed_data)\n",
    "    return stemmed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply this stemming function on content column which we are created by the cancatination of 'author' and 'title' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['content'] = news_dataset['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        darrel lucu hous dem aid even see comey letter...\n",
       "1        daniel j flynn flynn hillari clinton big woman...\n",
       "2                   consortiumnew com truth might get fire\n",
       "3        jessica purkiss civilian kill singl us airstri...\n",
       "4        howard portnoy iranian woman jail fiction unpu...\n",
       "                               ...                        \n",
       "20795    jerom hudson rapper trump poster child white s...\n",
       "20796    benjamin hoffman n f l playoff schedul matchup...\n",
       "20797    michael j de la merc rachel abram maci said re...\n",
       "20798    alex ansari nato russia hold parallel exercis ...\n",
       "20799                            david swanson keep f aliv\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in the above output there are no stopwords , uppercase words and signs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are separting the feature(x) and lable(y) values as we did it before on the basis of author and title but now the x will based on 'content' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = news_dataset['content'].values\n",
    "y = news_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
      " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
      " 'consortiumnew com truth might get fire' ...\n",
      " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
      " 'alex ansari nato russia hold parallel exercis balkan'\n",
      " 'david swanson keep f aliv'] (20800,)\n"
     ]
    }
   ],
   "source": [
    "print(x,x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1] (20800,)\n"
     ]
    }
   ],
   "source": [
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is TfidfVectorizer()\n",
    "\n",
    "The term tf–idf stands for term frequency–inverse document frequency. It is a mathematical statistic that is planned to reflect how significant a word is to a record in a collection or corpus. The tf–idf esteem builds proportionally to the number of times a word shows up in the document. It is offset by the quantity of documents in the corpus that contain the word, which helps to adjust for the fact that a few words show up more often when all is said and done. TF–IDF is one of the most well-known term-weighting plans today. An overview led in 2015 demonstrated that 83% of text-based recommender frameworks in advanced libraries use tf–idf. It would be difficult to understand tf–idf together. So, let's understand each separately-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Term Frequency (tf)- It gives us the recurrence of the word in each report in the corpus. It is the proportion of the number of times the word shows up in a report contrasted with the all-out the number of words in that record. It increments as the quantity of events of that word inside the record increments.\n",
    "\n",
    "Inverse Data Frequency (idf)- It is used to figure out the heaviness of uncommon words over all reports in the corpus. The words that occur seldom in the corpus have a high IDF score.\n",
    "\n",
    "Joining these two, we think of the TF-IDF score (w) for a word in a record in the corpus.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TD-IDF Example\n",
    "Let's take an example(A,B respectivily) to get more clear understanding.\n",
    "\n",
    "The cycle is ridden on the track.\n",
    "\n",
    "The bus is driven on the road.\n",
    "\n",
    "Let's assume the above two sentences are a separate document. Here, we have calculated the TF-IDF for the above two documents, which represent our corpus.\n",
    "\n",
    "Word\tTF\t\tIDF\t\tTF\t*\tIDF\n",
    "\n",
    " \t    A B\t \t\tA\t\tB\n",
    "\n",
    "The\t1/7\t 1/7\tlog(2/2) = 0\t       \t0\t0\n",
    "\n",
    "cycle 1/7\t0\tlog(2/1) = 0.3\t\t0.043\t0\n",
    "\n",
    "bus\t0\t1/7\tlog(2/1) = 0.3\t\t0\t0.043\n",
    "\n",
    "is\t1/7\t 1/7\tlog(2/2) = 0\t\t0\t0\n",
    "\n",
    "ridden\t1/7\t0\tlog(2/1) = 0.3\t\t0.043\t0\n",
    "\n",
    "driven\t0\t1/7\tlog(2/1) = 0.3\t\t0\t0.043\n",
    "\n",
    "on\t1/7\t1/7\tlog(2/2) = 0\t\t0\t0\n",
    "\n",
    "the\t1/7\t1/7\tlog(2/2) = 0\t\t0\t0\n",
    "\n",
    "track\t1/7\t0\tlog(2/1) = 0.3\t\t0.043\t0\n",
    "\n",
    "road\t0\t1/7\tlog(2/1) = 0.3\t\t0\t0.043\n",
    "\n",
    "\n",
    "In the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of \"cycle\" , \"bus\", \"ridden\", \"driven\", \"track\", and \"road\" are non-zero. These words have more significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Scikit-learn TfidfVectorizer\n",
    "\n",
    "Scikit-learn is a free software machine learning library for the Python programming language. It supports Python numerical and scientific libraries, in which TfidfVectorizer is one of them. It converts a collection of raw documents to a matrix of TF-IDF features. As tf–idf is very often used for text features, the class TfidfVectorizer combines all the options of CountVectorizer and TfidfTransformer into a single model. The TfidfVectorizer uses an in-memory vocabulary (a python dict) to map the most frequent words to feature indices and hence compute a word occurrence frequency (sparse) matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting the textual data into numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " vectorizer = TfidfVectorizer()\n",
    " vectorizer.fit(x)\n",
    "\n",
    " x = vectorizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15686)\t0.28485063562728646\n",
      "  (0, 13473)\t0.2565896679337957\n",
      "  (0, 8909)\t0.3635963806326075\n",
      "  (0, 8630)\t0.29212514087043684\n",
      "  (0, 7692)\t0.24785219520671603\n",
      "  (0, 7005)\t0.21874169089359144\n",
      "  (0, 4973)\t0.233316966909351\n",
      "  (0, 3792)\t0.2705332480845492\n",
      "  (0, 3600)\t0.3598939188262559\n",
      "  (0, 2959)\t0.2468450128533713\n",
      "  (0, 2483)\t0.3676519686797209\n",
      "  (0, 267)\t0.27010124977708766\n",
      "  (1, 16799)\t0.30071745655510157\n",
      "  (1, 6816)\t0.1904660198296849\n",
      "  (1, 5503)\t0.7143299355715573\n",
      "  (1, 3568)\t0.26373768806048464\n",
      "  (1, 2813)\t0.19094574062359204\n",
      "  (1, 2223)\t0.3827320386859759\n",
      "  (1, 1894)\t0.15521974226349364\n",
      "  (1, 1497)\t0.2939891562094648\n",
      "  (2, 15611)\t0.41544962664721613\n",
      "  (2, 9620)\t0.49351492943649944\n",
      "  (2, 5968)\t0.3474613386728292\n",
      "  (2, 5389)\t0.3866530551182615\n",
      "  (2, 3103)\t0.46097489583229645\n",
      "  :\t:\n",
      "  (20797, 13122)\t0.2482526352197606\n",
      "  (20797, 12344)\t0.27263457663336677\n",
      "  (20797, 12138)\t0.24778257724396507\n",
      "  (20797, 10306)\t0.08038079000566466\n",
      "  (20797, 9588)\t0.174553480255222\n",
      "  (20797, 9518)\t0.2954204003420313\n",
      "  (20797, 8988)\t0.36160868928090795\n",
      "  (20797, 8364)\t0.22322585870464118\n",
      "  (20797, 7042)\t0.21799048897828688\n",
      "  (20797, 3643)\t0.21155500613623743\n",
      "  (20797, 1287)\t0.33538056804139865\n",
      "  (20797, 699)\t0.30685846079762347\n",
      "  (20797, 43)\t0.29710241860700626\n",
      "  (20798, 13046)\t0.22363267488270608\n",
      "  (20798, 11052)\t0.4460515589182236\n",
      "  (20798, 10177)\t0.3192496370187028\n",
      "  (20798, 6889)\t0.32496285694299426\n",
      "  (20798, 5032)\t0.4083701450239529\n",
      "  (20798, 1125)\t0.4460515589182236\n",
      "  (20798, 588)\t0.3112141524638974\n",
      "  (20798, 350)\t0.28446937819072576\n",
      "  (20799, 14852)\t0.5677577267055112\n",
      "  (20799, 8036)\t0.45983893273780013\n",
      "  (20799, 3623)\t0.37927626273066584\n",
      "  (20799, 377)\t0.5677577267055112\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16996)\t0.09995656818816077\n",
      "  (0, 16928)\t0.3360072514082535\n",
      "  (0, 15295)\t0.09807665903342763\n",
      "  (0, 13914)\t0.3334797245354899\n",
      "  (0, 13014)\t0.2680313811122545\n",
      "  (0, 12501)\t0.3929876463935473\n",
      "  (0, 11936)\t0.24142639024498436\n",
      "  (0, 10306)\t0.09662001419895176\n",
      "  (0, 10219)\t0.3019527708144002\n",
      "  (0, 3155)\t0.3400831511004003\n",
      "  (0, 2794)\t0.3776836172783757\n",
      "  (0, 336)\t0.3360072514082535\n",
      "  (1, 16996)\t0.07263181421455335\n",
      "  (1, 15424)\t0.22579404836928033\n",
      "  (1, 15417)\t0.26613170238131584\n",
      "  (1, 15295)\t0.07126580880898774\n",
      "  (1, 13453)\t0.3387500815971264\n",
      "  (1, 11421)\t0.3084666283145136\n",
      "  (1, 10306)\t0.07020736153621741\n",
      "  (1, 10061)\t0.24924889065491332\n",
      "  (1, 9856)\t0.3387500815971264\n",
      "  (1, 5313)\t0.2768869285533855\n",
      "  (1, 2761)\t0.3387500815971264\n",
      "  (1, 2207)\t0.3387500815971264\n",
      "  (1, 956)\t0.2855580802628186\n",
      "  :\t:\n",
      "  (16637, 10008)\t0.32617532466383187\n",
      "  (16637, 9588)\t0.184164927958451\n",
      "  (16637, 8153)\t0.3214731053599403\n",
      "  (16637, 5009)\t0.3538476463585765\n",
      "  (16637, 1868)\t0.40919228974806576\n",
      "  (16637, 364)\t0.2848922858608963\n",
      "  (16638, 16457)\t0.307095142699481\n",
      "  (16638, 16092)\t0.31166809477415836\n",
      "  (16638, 12305)\t0.24545428213457152\n",
      "  (16638, 11871)\t0.30567916471209494\n",
      "  (16638, 7668)\t0.21891767805584614\n",
      "  (16638, 6163)\t0.34864155468839414\n",
      "  (16638, 6066)\t0.24737613258971647\n",
      "  (16638, 3782)\t0.6009306243123999\n",
      "  (16638, 307)\t0.25115645729407504\n",
      "  (16639, 13620)\t0.3626098009895325\n",
      "  (16639, 12906)\t0.33547035805786257\n",
      "  (16639, 11787)\t0.23229968883114552\n",
      "  (16639, 11155)\t0.2711393533267846\n",
      "  (16639, 6188)\t0.27993537585784406\n",
      "  (16639, 4625)\t0.20905678504065878\n",
      "  (16639, 3147)\t0.3439671543920653\n",
      "  (16639, 1468)\t0.4363161280786969\n",
      "  (16639, 961)\t0.27647936423932473\n",
      "  (16639, 184)\t0.34828080184930743 (16640, 17128)\n"
     ]
    }
   ],
   "source": [
    "print(x_train, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12801)\t0.2910746804557067\n",
      "  (0, 9818)\t0.30786004182651133\n",
      "  (0, 7668)\t0.22945314906455008\n",
      "  (0, 6816)\t0.16094563145945953\n",
      "  (0, 6289)\t0.288254092437116\n",
      "  (0, 5941)\t0.288254092437116\n",
      "  (0, 5233)\t0.21316265672448448\n",
      "  (0, 4346)\t0.3250084367199054\n",
      "  (0, 3395)\t0.3301936745912874\n",
      "  (0, 2959)\t0.24534646237198773\n",
      "  (0, 1667)\t0.30373060380734146\n",
      "  (0, 908)\t0.213510750423647\n",
      "  (0, 239)\t0.34297808354766485\n",
      "  (1, 16996)\t0.09117761343372983\n",
      "  (1, 15295)\t0.08946281236254729\n",
      "  (1, 14046)\t0.42524648908354634\n",
      "  (1, 13190)\t0.36773046084789346\n",
      "  (1, 12741)\t0.24868518461414146\n",
      "  (1, 12279)\t0.3796661151115819\n",
      "  (1, 12041)\t0.37327055071909065\n",
      "  (1, 10306)\t0.08813410128297053\n",
      "  (1, 8813)\t0.42524648908354634\n",
      "  (1, 4008)\t0.23098933893199997\n",
      "  (1, 3339)\t0.2834482751186189\n",
      "  (2, 16868)\t0.344315415802567\n",
      "  :\t:\n",
      "  (4158, 16782)\t0.2796201559111399\n",
      "  (4158, 13954)\t0.2713157796360236\n",
      "  (4158, 13918)\t0.29432702492466434\n",
      "  (4158, 13775)\t0.21479309786895925\n",
      "  (4158, 13600)\t0.2496550139728973\n",
      "  (4158, 11068)\t0.29432702492466434\n",
      "  (4158, 10670)\t0.24617506104822148\n",
      "  (4158, 5768)\t0.32934072196545544\n",
      "  (4158, 3549)\t0.2872208032582607\n",
      "  (4158, 2510)\t0.22655297584422188\n",
      "  (4158, 1296)\t0.30891064506142396\n",
      "  (4158, 273)\t0.293231224080478\n",
      "  (4158, 152)\t0.20393904870694302\n",
      "  (4159, 16996)\t0.11013119816597862\n",
      "  (4159, 15295)\t0.10805993210105909\n",
      "  (4159, 14927)\t0.3088818119678944\n",
      "  (4159, 10306)\t0.10645501464709921\n",
      "  (4159, 6188)\t0.2892693295339005\n",
      "  (4159, 5152)\t0.3423702044974272\n",
      "  (4159, 3150)\t0.3072250132435665\n",
      "  (4159, 2998)\t0.3779346456675232\n",
      "  (4159, 2824)\t0.3186116682102382\n",
      "  (4159, 1208)\t0.3635178622548901\n",
      "  (4159, 566)\t0.32177779021833913\n",
      "  (4159, 347)\t0.3068192329139987 (4160, 17128)\n"
     ]
    }
   ],
   "source": [
    "print(x_test, x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1] (16640,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0] (4160,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for training data\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_of_training_data = model.predict(x_train)\n",
    "prediction_of_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation(checking the accuracy score of our model on the training data & test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy score for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of traing data is : 0.9865985576923076\n"
     ]
    }
   ],
   "source": [
    "accuracy_of_training_prediction = accuracy_score(prediction_of_training_data,y_train)\n",
    "print(\"The accuracy score of traing data is :\",accuracy_of_training_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for test data\n",
    "model.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for test data\n",
    "prediction_of_test_data = model.predict(x_test)\n",
    "prediction_of_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of test data is : 0.9795673076923077\n"
     ]
    }
   ],
   "source": [
    "accuracy_of_test_prediction = accuracy_score(prediction_of_test_data,y_test)\n",
    "print(\"The accuracy score of test data is :\",accuracy_of_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "This news is fake !\n"
     ]
    }
   ],
   "source": [
    "#so first take the very first news from the test data as we can see that this first news is fake = 1\n",
    "\n",
    "x_new = x_test[0]\n",
    "x_new_prediction = model.predict(x_new)\n",
    "print(x_new_prediction)\n",
    "\n",
    "if x_new_prediction == 1:\n",
    "    print(\"This news is fake !\")\n",
    "else:\n",
    "    print(\"This news is orignal or not fake ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "This news is orignal or not fake !\n"
     ]
    }
   ],
   "source": [
    "#so take the 2nd news from the test data as we can see in test data that this 2nd news is orignal = 0\n",
    "\n",
    "x_new = x_test[1]\n",
    "x_new_prediction = model.predict(x_new)\n",
    "print(x_new_prediction)\n",
    "\n",
    "\n",
    "if x_new_prediction == 1:\n",
    "    print(\"This news is fake !\")\n",
    "else:\n",
    "    print(\"This news is orignal or not fake !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hence Completed !***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________ Best Wishes & Hope for the best ___________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89d0d3bf106da59c6cfa35039bcefe2e9c89bd464d61a90bb83c03f19368811b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
